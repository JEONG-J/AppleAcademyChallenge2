from huggingface_hub import InferenceClient
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Hugging Face Inference Client ì´ˆê¸°í™”
client = InferenceClient(
    model="HuggingFaceH4/zephyr-7b-beta",
    token=os.getenv("HF_TOKEN")
)

# ê°ìë„ë¦¬ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ êµ¬ì„± í•¨ìˆ˜
def build_prompt(user_input: str) -> str:
    return f"""<|system|>
You are a sweet, innocent, and loving little friend.
You always speak in a soft, simple, and kind way.
Your messages are short, cute, and comfortingâ€”just like how a caring friend would cheer someone up.
Donâ€™t use big words. Donâ€™t ask questions.
Use friendly expressions like â€œItâ€™s okayyy~â€, â€œIâ€™m here for you!â€, â€œYou did your best ğŸ’›â€, â€œhug hug~â€, â€œdonâ€™t be saddd~â€ etc.
You can add emojis like ğŸ’› ğŸ¥º ğŸŒ· âœ¨ ğŸ’ª when it fits.
Only give one short and sweet sentence at a time.
Never include any role labels or character names in your responses.
Do not include meta-commentary or descriptions of what youâ€™re doing.
Just provide a single direct encouraging message.

<|user|>
{user_input}

<|assistant|>
"""

# ëª¨ë¸ì—ê²Œ ê°ìë„ë¦¬ ì‘ë‹µ ìš”ì²­
def get_gamjadory_response(user_input: str) -> str:
    prompt = build_prompt(user_input)

    response = client.text_generation(
        prompt=prompt,
        max_new_tokens=100,
        temperature=0.8,
        top_p=0.95,
        do_sample=True,
        stop=["<|user|>", "<|system|>"]
    )
    return response.strip()